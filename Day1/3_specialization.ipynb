{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42d3d18f",
   "metadata": {},
   "source": [
    "# Code Specialization\n",
    "\n",
    "To be fast, Julia needs to **specialize** code, that is compile specific native versions of the code. **The better the specialization the faster the code!** In the following we will investigate how Julia achieves good code specialization while retaining the power of generic programming."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6add0fc5",
   "metadata": {},
   "source": [
    "## Just Ahead of Time (JAOT) Compilation\n",
    "\n",
    "<p><img src=\"../imgs/from_source_to_native.png\" alt=\"drawing\" width=\"800\"/></p>\n",
    " \n",
    "\n",
    "**AST = Abstract Syntax Tree**\n",
    "\n",
    "**IR = Intermediate Representation**\n",
    "\n",
    "**SSA = Static Single Assignment**\n",
    "\n",
    "**[LLVM](https://de.wikipedia.org/wiki/LLVM) = Low Level Virtual Machine**\n",
    "\n",
    "## Specialization\n",
    "\n",
    "**Julia specializes on the types of function arguments**, i.e. Julia compiles efficient machine code for the given input types, **when a function is called for the first time**.\n",
    "\n",
    "If it is called again, the already existing machine code is reused, until we call the function with different input types.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2352e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "func(x,y) = 2x + y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa5f7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [1.2, 3.4, 5.6] # Vector{Float64}\n",
    "y = [0.4, 0.7, 0.9] # Vector{Float64}\n",
    "\n",
    "@time func(x,y);\n",
    "@time func(x,y);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a475ea",
   "metadata": {},
   "source": [
    "**First call:** compilation + running the code\n",
    "\n",
    "**Second call:** running the code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44115394",
   "metadata": {},
   "outputs": [],
   "source": [
    "@time func(x,y);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74b788e",
   "metadata": {},
   "source": [
    "If one of the input types changes, Julia compiles a new specialization of the function!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21df8af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "typeof(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4add9224",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [1, 3, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb28c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "typeof(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49854ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "@time func(x,y); # Vector{Int64}, Vector{Float64}\n",
    "@time func(x,y);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c9af6e-a348-4871-aa89-53f310098baa",
   "metadata": {},
   "source": [
    "We now have two efficient native codes in the cache: one for all `Vector{Float64}` inputs and another one for `Vector{Int64}` as the first and `Vector{Float64}` as the second argument type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee58ca00-ff3b-42fa-a34a-5500f0202c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "using MethodAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b8c246-cad7-4155-8fc5-899862be6cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "methods(func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8254a81-c2a3-4773-9c4f-7ed7ef160dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "methodinstances(func)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b6c894-0b8b-4457-aa21-c82389fa7671",
   "metadata": {},
   "source": [
    "## Introspection\n",
    "#### (*But I really want to see what happens!*)\n",
    "\n",
    "We can inspect the code at all transformation stages with a bunch of macros:\n",
    "\n",
    "<img src=\"../imgs/julia_introspection_macros.png\" width=350px>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37142078-1109-43d0-ab3b-a6af1f69bc91",
   "metadata": {},
   "outputs": [],
   "source": [
    "@macroexpand @time 3+3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248008eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "@code_lowered func(1.0,2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a0d257",
   "metadata": {},
   "outputs": [],
   "source": [
    "@code_typed func(1.0,2.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da51e422-1f83-4f56-9761-4f915612dc5d",
   "metadata": {},
   "source": [
    "From the types of the input arguments, Julia has figured out all the intermediate types and replaced the generic functions `*` and `+` by specific implementations. This crucial process is known as **type inference** and its success is the basis for a good specialization (i.e. performant native code as a result). It will concern us in much more detail tomorrow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72a453c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@code_llvm func(1.0,2.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a6a4e41",
   "metadata": {},
   "source": [
    "We can remove the comments (lines starting with `;` using `debuginfo=:none`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a33e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "@code_llvm debuginfo=:none func(1.0,2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae32331",
   "metadata": {},
   "outputs": [],
   "source": [
    "@code_native debuginfo=:none syntax=:intel func(1.0,2.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b6ed56",
   "metadata": {},
   "source": [
    "Let's compare this to integer input.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6e9653",
   "metadata": {},
   "outputs": [],
   "source": [
    "@code_native debuginfo=:none syntax=:intel func(1,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45872508",
   "metadata": {},
   "source": [
    "## How important is specialization?\n",
    "\n",
    "Let's try to estimate the performance gain by specialization.\n",
    "\n",
    "To prevent specialization, we deliberately throw away any useful type information and operate on a `Vector{Any}` that can literally store anything!\n",
    "\n",
    "(This is qualitatively comparable to what Python does.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307bed1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "func(v) = 2*v[1] + v[2] # version of func that takes in a vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef3134a-027f-41c3-8d7f-11ffe11ca355",
   "metadata": {},
   "outputs": [],
   "source": [
    "rand(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c6ae38-70dd-42a3-a723-8b4eea2bacab",
   "metadata": {},
   "outputs": [],
   "source": [
    "Any[rand(), rand()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7eadf19",
   "metadata": {},
   "outputs": [],
   "source": [
    "using BenchmarkTools\n",
    "\n",
    "@btime func(v) setup=(v=rand(2));\n",
    "@btime func(v) setup=(v=Any[rand(), rand()]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181c0a60",
   "metadata": {},
   "source": [
    "**That's a huge slowdown!**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaaf2ba3-ac9b-4cdf-a5a0-17e748f1b4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "@code_typed func(rand(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70cd881-b2f0-4559-8015-5953c3fea257",
   "metadata": {},
   "outputs": [],
   "source": [
    "@code_typed func(Any[rand(), rand()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5cbbc7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @code_native debuginfo=:none syntax=:intel func(rand(2))\n",
    "# @code_native debuginfo=:none syntax=:intel func(Any[rand(), rand()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5f9544",
   "metadata": {},
   "source": [
    "## Types vs values\n",
    "\n",
    "In high performance computing, compilation time (order of seconds or minutes) is typically neglectable compared to the actual time it takes to perform the computation (readily on the orders of hours/days/weeks). Therefore, we generally want to optimize for runtime efficiency even if this means that compilation time goes up by a reasonable amount.\n",
    "\n",
    "**Julia specializes on input types and not values!**\n",
    "\n",
    "Primarily it is **type information** that is used by the compiler to specialize code. (There are special techniques like, e.g., constant propagation and others that we are neglecting here.)\n",
    "\n",
    "(Very) roughly speaking, the more information there is in *type space* (e.g. in type parameters) the higher the likelihood that the compiler produces fast and efficient code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0af51d7-1d2c-416c-a935-440012155dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = rand(10,10);\n",
    "B = rand(10,10);\n",
    "@btime $A + $B;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b5657f-825a-4211-9848-46351c589afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "typeof(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f87615-b7bc-4c32-a775-5e8c41704880",
   "metadata": {},
   "outputs": [],
   "source": [
    "size(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2fb5d0-c3c7-487d-a7a0-13ca16502dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "size(typeof(A)) # the size of A isn't type information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0479abf8-6736-496a-8edc-8d448c914ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "using StaticArrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b3c143-ed54-4646-82e9-bbfd9e341c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = @SMatrix rand(10,10);\n",
    "B = @SMatrix rand(10,10);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67369e7-e0a7-4394-a762-2e01f327a6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "typeof(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54aeddb0-6785-41ce-94c6-e14a8b42a979",
   "metadata": {},
   "outputs": [],
   "source": [
    "size(typeof(A)) # the size of A is type information!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1923b787-c8f6-4f71-802b-b18580412fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "@btime $A + $B;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db23462-d3a6-4959-abb5-0f3343a69a2d",
   "metadata": {},
   "source": [
    "**StaticArrays.jl**\n",
    "\n",
    "```\n",
    "============================================\n",
    "    Benchmarks for 3Ã—3 Float64 matrices\n",
    "============================================\n",
    "Matrix multiplication               -> 5.9x speedup\n",
    "Matrix multiplication (mutating)    -> 1.8x speedup\n",
    "Matrix addition                     -> 33.1x speedup\n",
    "Matrix addition (mutating)          -> 2.5x speedup\n",
    "Matrix determinant                  -> 112.9x speedup\n",
    "Matrix inverse                      -> 67.8x speedup\n",
    "Matrix symmetric eigendecomposition -> 25.0x speedup\n",
    "Matrix Cholesky decomposition       -> 8.8x speedup\n",
    "Matrix LU decomposition             -> 6.1x speedup\n",
    "Matrix QR decomposition             -> 65.0x speedup\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c1f27c-daf2-4072-b165-847af504760e",
   "metadata": {},
   "source": [
    "### Why not always use static arrays then?!\n",
    "\n",
    "By putting more information in the type you are putting more stress on the compiler to optimize things.\n",
    "\n",
    "Specifically, if static arrays are too big compile time can explode or the compiler might just give up and fall back to an inefficient default version.\n",
    "\n",
    "Generally speaking, static arrays are only useful as small fixed-size arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4001e71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # should take (much) longer to compile and the speedup should be gone as well\n",
    "# # if it isn't, increase N a little bit\n",
    "# N = 50\n",
    "# M = rand(N,N);\n",
    "# Mstatic = SMatrix{N,N}(M);\n",
    "\n",
    "# @btime $Mstatic + $Mstatic;\n",
    "# @btime $M + $M;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73d775e-d103-46b4-9df7-6d99cfe6a0d9",
   "metadata": {},
   "source": [
    "### Dispatch and specialization\n",
    "\n",
    "Having a reasonable amount of information encoded in the type domain isn't only useful to help the compiler (specialization) but also for dispatching to the most specific (and therefore hopfully most performant) method of a function.\n",
    "\n",
    "**Types drive both specialization and multiple dispatch!**\n",
    "\n",
    "In this sense, multiple dispatch is essentially the first step of the specialization process where Julia chooses between different implementations.\n",
    "\n",
    "#### Example: Determinant of a 2x2 matrix\n",
    "\n",
    "Let's say your task would be to write a function computing the determinant of a 2x2 matrix. How would you implement it?\n",
    "\n",
    "Probably you'd say, well I know the formula for computing the determinant of a 2x2 matrix! Let's just implement it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a289b82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "det_2x2(X) = X[1,1] * X[2,2] - X[1,2] * X[2,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9090407",
   "metadata": {},
   "outputs": [],
   "source": [
    "M = [1 2; 3 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b039f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "det_2x2(M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af901176",
   "metadata": {},
   "outputs": [],
   "source": [
    "@btime det_2x2(M);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac3e1c3e",
   "metadata": {},
   "source": [
    "Let's see how Julia's built-in `det` function compares to our algorithm:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5bc6916",
   "metadata": {},
   "outputs": [],
   "source": [
    "using LinearAlgebra\n",
    "\n",
    "det(M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b503641",
   "metadata": {},
   "outputs": [],
   "source": [
    "@btime det(M);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef07dce3",
   "metadata": {},
   "source": [
    "It's much slower!!\n",
    "\n",
    "The reason isn't just that the compiler doesn't just know the size of the matrix from its type but also that [the code it considers](https://github.com/JuliaLang/julia/blob/release-1.8/stdlib/LinearAlgebra/src/generic.jl#L1544-L1550) (selected by the dispatch mechanism) is too general to compete with our implementation in `det_2x2`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1339503",
   "metadata": {},
   "source": [
    "Let's now move the size information to the type domain and see how things change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a5d12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "using StaticArrays\n",
    "S = @SMatrix [1 2; 3 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3550b299-21fd-47cb-a56e-a3d4b1e478f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "@btime det($S);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7538c736",
   "metadata": {},
   "source": [
    "Note that it is super faster because StaticArrays.jl provides [a hand-coded version](https://github.com/JuliaArrays/StaticArrays.jl/blob/master/src/det.jl#L10-L12), similar to our `det_2x2` above, which gets selected because of the size information in the type.\n",
    "\n",
    "The (tiny) speed difference compared to our own `det_2x2` is only due to bounds checking and matrix vs linear indexing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967173a5-ee6b-4e90-b908-2077b084acc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "det_2x2_optimized(X) = X[1] * X[4] - X[3] * X[2]\n",
    "@btime det_2x2_optimized($M);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441bd83f",
   "metadata": {},
   "source": [
    "## Are explicit type annotations necessary? (think C or Fortran)\n",
    "\n",
    "Note that Julia's type inference is powerful. Specifying types **is not** necessary for best performance!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa6dc3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "function my_function(x)\n",
    "    y = rand()\n",
    "    z = rand()\n",
    "    x+y+z\n",
    "end\n",
    "\n",
    "function my_function_typed(x::Int)::Float64\n",
    "    y::Float64 = rand()\n",
    "    z::Float64 = rand()\n",
    "    x+y+z\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9508d8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "@btime my_function(10);\n",
    "@btime my_function_typed(10);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e289d4e-1f72-4f8b-9a4b-b5ae6d39dc38",
   "metadata": {},
   "source": [
    "Annotating types explicitly can serve a purpose.\n",
    "\n",
    "* Enforce conversions\n",
    "* Very rarely: help the compiler infer types in tricky situations\n",
    "\n",
    "However, more often than not it is an indication of suboptimal code design. (It also makes functions much less generic and reusable!)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7decf680-6766-4e52-a75e-530ff7abd65a",
   "metadata": {},
   "source": [
    "# Core messages of this Notebook\n",
    "\n",
    "* **A function is compiled when called for the first time** with a given set of argument types.\n",
    "* The are **multiple compilation steps** which can be inspected through macros like `@code_warntype`.\n",
    "* **Code specialization** based on the types of all of the input arguments is important for speed.\n",
    "* Critical information can be moved to the **type domain** for better dispatch and specialization.\n",
    "* In virtually all cases, **explicit type annotations are irrelevant for performance**."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.0",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

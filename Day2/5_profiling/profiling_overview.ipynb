{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Profiling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we have seen, [BenchmarkTools.jl](https://github.com/JuliaCI/BenchmarkTools.jl) provides the necessary tools to micro-benchmark a certain piece of Julia code. However, sometimes we want to zoom out and identify bottlenecks in a larger block of code.\n",
    "\n",
    "There are two different techniques that we'll use:\n",
    "* **Instrumented** profiling\n",
    "* **Statistical** profiling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Matrix-Multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function matmul(n, k=n)\n",
    "    A = rand(n, k)\n",
    "    B = rand(k, n)\n",
    "    C = zeros(n, n)\n",
    "    # simple matmul implementation\n",
    "    for n in axes(C, 2), m in axes(C, 1)\n",
    "        Cmn = zero(eltype(C))\n",
    "        for k in axes(A, 2)\n",
    "            tmp = A[m, k] * B[k, n]\n",
    "            Cmn += tmp\n",
    "        end\n",
    "        C[m, n] = Cmn\n",
    "    end\n",
    "    return C\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matmul(10, 5); # trigger compilation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instrumented Profiling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea is to modify our code and explicitly add profiling bits to it. Specifically, we'll use [TimerOutputs.jl](https://github.com/KristofferC/TimerOutputs.jl).\n",
    "\n",
    "**Pros**\n",
    "* Accurate and complete performance statistics\n",
    "\n",
    "**Cons**\n",
    "* Need to modify the source code\n",
    "* Some overhead\n",
    "* Limited support for multithreading ([TrackingTimers.jl](https://github.com/ericphanson/TrackingTimers.jl) may be an alternative)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using TimerOutputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function matmul_instrumented(n, k=n)\n",
    "    @timeit \"initialize matrices\" begin\n",
    "        @timeit \"init A\" A = rand(n, k)\n",
    "        @timeit \"init B\" B = rand(k, n)\n",
    "        @timeit \"init C\" C = zeros(n, n)\n",
    "    end\n",
    "    # simple matmul implementation\n",
    "    @timeit \"matmul\" for n in axes(C, 2), m in axes(C, 1)\n",
    "        Cmn = zero(eltype(C))\n",
    "        for k in axes(A, 2)\n",
    "            @timeit \"mul\" tmp = A[m, k] * B[k, n]\n",
    "            @timeit \"add\" Cmn += tmp\n",
    "        end\n",
    "        C[m, n] = Cmn\n",
    "    end\n",
    "    return C\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to = TimerOutputs.get_defaulttimer()\n",
    "# TimerOutputs.reset_timer!(to)\n",
    "matmul_instrumented(100, 10);\n",
    "to"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical Profiling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea is to repeatedly record the state of the program (i.e. which line or function is currently executing) while it is running with a given sample rate.\n",
    "\n",
    "Julia has built-in [statistical profilers](https://goo.gl/Ycz4Td) in the standard library [`Profile`](https://docs.julialang.org/en/v1/stdlib/Profile/) (see also [here](https://docs.julialang.org/en/v1/manual/profile/)). We will use these profilers to identify the parts of our `matmul` function that have\n",
    "* the highest computation time\n",
    "* make the most / the biggest allocations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Profiling is as simple as prepending the function call by the `@profile` macro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Profile\n",
    "Profile.clear() # clean up old profiling data\n",
    "@profile matmul(1000, 100);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most basic way to analyze the profiling results is `Profile.print()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Profile.print(; threads=1, format=:flat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A much nicer way to analyze the profiling results is to visualize them as a flame graph. In principle, one can choose from a number of visualization tools. To name a few:\n",
    "\n",
    "* [ProfileView.jl](https://github.com/timholy/ProfileView.jl)\n",
    "* [ProfileVega.jl](https://github.com/davidanthoff/ProfileVega.jl)\n",
    "* [ProfileSVG.jl](https://github.com/kimikage/ProfileSVG.jl)\n",
    "* [PProf.jl](https://github.com/JuliaPerf/PProf.jl)\n",
    "* ...\n",
    "\n",
    "However, personally, I recommend to use the [Julia extension for Visual Studio Code (VS Code)](https://www.julia-vscode.org/) which has built-in [profiling visualization capabilities](https://www.julia-vscode.org/docs/stable/userguide/profiler/). Let's take a closer look..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra: Hardware-Level Performance Monitoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we have considered **software** profiling options. Another approach to assessing the performance of a (piece of) Julia code are **hardware** performance counters, which are built into most modern CPUs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To utilize those counters in Julia, one can use **[LIKWID.jl](https://github.com/JuliaPerf/LIKWID.jl)** which is a wrapper around the performance monitoring and benchmarking suite [LIKWID](https://github.com/RRZE-HPC/likwid) (Like I Knew What I'm Doing) by the [Erlangen National High Performance Computing Center (NHR@FAU)](https://hpc.fau.de/). Conceptually, it provides tools for both instrumented (e.g. marker API) and statistical (e.g. timeline and stethoscope mode) performance monitoring.\n",
    "\n",
    "<div style=\"float\">\n",
    "    <img src=\"../../imgs/likwidjl_logo.png\" width=350px>\n",
    "    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "    <img src=\"../../imgs/likwid_logo.png\" width=300px>\n",
    "</div>\n",
    "\n",
    "**LIKWID.jl** allows one to obtain detailed low-performance metrics for a (piece of) Julia code to answer questions such as\n",
    "* How many FLOPs have been performed?\n",
    "* What fraction of the FLOPs have been vectorized? (SIMD)\n",
    "* How much data has been read from / written to memory?\n",
    "\n",
    "**Most important commands:**\n",
    "\n",
    "* `PerfMon.supported_groups()`: List all available performance groups (\"what to measure\").\n",
    "  * Examples:\n",
    "    * \"FLOPS_SP\" / \"FLOPS_DP\": single or double precision floating point operations\n",
    "    * \"MEM\": memory related metrics\n",
    "* `@perfmon <performance_group> <code>`\n",
    "  * Example: `@perfmon \"FLOPS_DP\" myfunc(x)`.\n",
    "\n",
    "[Demonstration on the cluster...]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more information see:\n",
    "* [LIKWID.jl Documentation](https://juliaperf.github.io/LIKWID.jl/dev/)\n",
    "* [JuliaCon2022 Talk (Youtube)](https://www.youtube.com/watch?v=l2fTNfEDPC0)\n",
    "* [LIKWID Wiki](https://github.com/RRZE-HPC/likwid/wiki)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../../imgs/likwid_example.png\" width=900px>"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Julia 1.8.0",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

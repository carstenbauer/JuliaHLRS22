{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SIMD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SIMD stands for **\"Single Instruction Multiple Data\"** and falls into the category of instruction level parallelism (vector instructions). Consider this simple example where `A`, `B`, and `C` are vectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function vector_add(A, B, C)\n",
    "    for i in eachindex(A, B, C)\n",
    "        @inbounds A[i] = B[i] + C[i]\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The idea behind SIMD is to perform the add instruction on multiple elements at the same time (instead of separately performing them one after another). The process of splitting up the simple loop addition into multiple vector additions is often denoted as \"loop vectorization\". Since each vectorized addition happens at instruction level, i.e. within a CPU core, the feature set of the CPU determines how many elements we can process in one go."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../../imgs/simd_vaddpd.png\" width=300px>\n",
    "<img src=\"../../imgs/simd_register_width.png\" width=400px>\n",
    "\n",
    "(**Source:** Node-level performance engineering course by [NHR@FAU](https://hpc.fau.de/))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check which \"advanced vector extensions\" (AVX) the system supports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using CpuId\n",
    "cpuinfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter(x -> contains(string(x), \"AVX\"), cpufeatures())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIZE = 512 * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = rand(Float64, SIZE)\n",
    "B = rand(Float64, SIZE)\n",
    "C = rand(Float64, SIZE);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@code_native debuginfo=:none syntax=:intel vector_add(A,B,C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## It's not always so simple: Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function vector_dot(B, C)\n",
    "    a = zero(eltype(B))\n",
    "    for i in eachindex(B,C)\n",
    "        @inbounds a += B[i] * C[i]\n",
    "    end\n",
    "    return a\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@code_native debuginfo=:none syntax=:intel vector_dot(B, C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the `vaddsd` instruction and usage of `xmmi` registers (128 bit)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How could this loop be vectorized?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function vector_dot_unrolled4(B, C)\n",
    "    a1 = zero(eltype(B))\n",
    "    a2 = zero(eltype(B))\n",
    "    a3 = zero(eltype(B))\n",
    "    a4 = zero(eltype(B))\n",
    "    @inbounds for i in 1:4:length(B)-4\n",
    "        a1 += B[i] * C[i]\n",
    "        a2 += B[i+1] * C[i+1]\n",
    "        a3 += B[i+2] * C[i+2]\n",
    "        a4 += B[i+3] * C[i+3]\n",
    "    end\n",
    "    return a1+a2+a3+a4\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@code_native debuginfo=:none syntax=:intel vector_dot_unrolled4(B, C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using BenchmarkTools\n",
    "@btime vector_dot($B, $C);\n",
    "@btime vector_dot_unrolled4($B, $C);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To \"force\" automatic SIMD vectorization in Julia, you can use the `@simd` macro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function vector_dot_simd(B, C)\n",
    "    a = zero(eltype(B))\n",
    "    @simd for i in eachindex(B,C)\n",
    "        @inbounds a += B[i] * C[i]\n",
    "    end\n",
    "    return a\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By using the `@simd` macro, we are asserting several properties of the loop:\n",
    "\n",
    "* It is safe to execute iterations in arbitrary or overlapping order, with special consideration for reduction variables.\n",
    "* Floating-point operations on reduction variables can be reordered, possibly causing different results than without `@simd`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@btime vector_dot_simd($B, $C);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a huge speedup for just a little extra `@simd`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@code_native debuginfo=:none syntax=:intel vector_dot_simd(B, C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the `vfmadd231pd` instruction and usage of `ymmi` AVX registers (256 bit)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data types matter:\n",
    "* Floating-point addition is **non-associative** and the order of operations is important.\n",
    "* Integer addition is **associative** and the order of operations has no impact."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check what happens for `Int64` input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B_int = rand(Int64, SIZE)\n",
    "C_int = rand(Int64, SIZE)\n",
    "@btime vector_dot($B_int, $C_int);\n",
    "@btime vector_dot_simd($B_int, $C_int);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, there is no difference between the two variants."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SIMD is hard..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Autovectorization is a hard problem (it needs to prove a lot of things about the code!)\n",
    "* Not every code / loop is readily vectorizable\n",
    "  * Keep your loops simple, e.g. avoid conditionals, control flow, and function calls if possible!\n",
    "  * Loop length should be countable up front\n",
    "  * Contiguous data access\n",
    "  * (Align data structures to SIMD width boundary)\n",
    "\n",
    "**Keep it simple!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [LoopVectorization.jl](https://github.com/JuliaSIMD/LoopVectorization.jl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Think of `@turbo` as a more sophisticated version of `@simd`. Hopefully, these features will at some point just be part of Julia's compiler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using LoopVectorization\n",
    "\n",
    "function vector_dot_turbo(B, C)\n",
    "    a = zero(eltype(B))\n",
    "    @turbo for i in eachindex(B,C)\n",
    "        @inbounds a += B[i] * C[i]\n",
    "    end\n",
    "    return a\n",
    "end\n",
    "\n",
    "@btime vector_dot_simd($B, $C);\n",
    "@btime vector_dot_turbo($B, $C);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@code_native debuginfo=:none syntax=:intel vector_dot_turbo(B, C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the usage of the `zmmi` AVX512 registers! (512 bit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structure of Array vs Array of Structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data layout can matter!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Array of structure\n",
    "AoS = [complex(rand(),rand()) for i in 1:SIZE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@btime sum($AoS);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [StructArrays.jl](https://github.com/JuliaArrays/StructArrays.jl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using StructArrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SoA = StructArray{Complex}((rand(SIZE), rand(SIZE)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@btime sum($SoA);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Resources:**\n",
    "\n",
    "* [LoopVectorization.jl video on youtube](https://www.youtube.com/watch?v=qz2kJdVDWi0)\n",
    "* [SIMD and SIMD-intrinsics in Julia](http://kristofferc.github.io/post/intrinsics/)\n",
    "* [Optimizing Serial Code](https://mitmath.github.io/18337/lecture2/optimizing)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.0",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

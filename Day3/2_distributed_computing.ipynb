{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distributed Computing: `Distributed` standard library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What**\n",
    "* **single Julia process -> multiple Julia processes** that coordinate to perform certain computations\n",
    "\n",
    "**Why**\n",
    "* Scaling things up: run computations on multiple CPU cores, potentially even on different machines, e.g. nodes of a supercomputer or a local cluster of desktop machines.\n",
    "* Effectively increase your memory: process a large dataset, which wouldn't fit into local memory, in parallel across multiple machines with separate dedicated RAM.\n",
    "\n",
    "**Julia provides two fundamental implementations and paradigms**\n",
    "* Julia's built-in [`Distributed` standard library](https://docs.julialang.org/en/v1/stdlib/Distributed/)\n",
    "  * master-worker model\n",
    "* [Message Passing Interface (MPI)](https://www.mpi-forum.org/) through [MPI.jl](https://github.com/JuliaParallel/MPI.jl)\n",
    "  * Single Program Multiple Data (SPMD)\n",
    "  \n",
    "The focus of this notebook is on the **`Distributed` standard library.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Distributed` standard library\n",
    "\n",
    "Julia's `Distributed` follows a master-worker paradigm for its native distributed parallelism: **One master process coordinates all the worker processes, which perform the actual computations.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Distributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nprocs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nworkers() # the master is considered a worker as long as there are no real workers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To increase the number of workers, i.e. Julia processes, from within a Julia session we can dynamically call **`addprocs`**.\n",
    "\n",
    "Alternatively, when starting Julia from the command line, one can use the `-p` option up front. Example,\n",
    "\n",
    "```\n",
    "julia -p 4\n",
    "```\n",
    "\n",
    "will start Julia with 5 processes, 1 master and 4 workers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element Vector{Int64}:\n",
       " 2\n",
       " 3\n",
       " 4\n",
       " 5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "addprocs(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every process has a Julia internal `pid` (process id). The master is always 1. You can get the workers pids from `workers()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element Vector{Int64}:\n",
       " 2\n",
       " 3\n",
       " 4\n",
       " 5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "workers()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the 4 worker's pids aren't necessarily 2, 3, 4 and 5 and one shouldn't rely on those literal values. Let's remove the processes and add them once more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Task (done) @0x0000000119edacb0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rmprocs(workers())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nworkers() # only the master is left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element Vector{Int64}:\n",
       " 6\n",
       " 7\n",
       " 8\n",
       " 9"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "addprocs(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element Vector{Int64}:\n",
       " 6\n",
       " 7\n",
       " 8\n",
       " 9"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "workers()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One master to rule them all - `@spawn`, `@spawnat`, `@fetch`, `@fetchfrom`, `@everywhere`..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To execute commands and start computations on workers we can use the following macros\n",
    "\n",
    "* `@spawn`: run a command or a code block on any worker and return a `Future` to it's result. It's basically a version of `@async` for remote processes.\n",
    "* `@spawnat`: same as `@spawn` but one can choose a specific worker by providing its pid."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example:** Let's say we would like to generate a random matrix on one of the workers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Future(8, 1, 24, ReentrantLock(nothing, 0x00000000, 0x00, Base.GenericCondition{Base.Threads.SpinLock}(Base.InvasiveLinkedList{Task}(nothing, nothing), Base.Threads.SpinLock(0)), (3, 4294967296, 4520084976)), nothing)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@spawn 3+3 # similar to @async"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Future(9, 1, 25, ReentrantLock(nothing, 0x00000000, 0x00, Base.GenericCondition{Base.Threads.SpinLock}(Base.InvasiveLinkedList{Task}(nothing, nothing), Base.Threads.SpinLock(0)), (1, 4964320784, 107374182406)), nothing)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = @spawn 3+3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fetch(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the combination of spawning at fetching is so common, there is `@fetch` which combines them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@fetch 3+3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3Ã—3 Matrix{Float64}:\n",
       " 0.0725835  0.145207   0.582114\n",
       " 0.69949    0.0627775  0.721059\n",
       " 0.0933021  0.660484   0.235878"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@fetch rand(3,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which worker did the work?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      From worker 8:\t8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@fetch begin\n",
    "    println(myid());\n",
    "    3+3\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `@spawnat` and `@fetchfrom` we can delegate the work to a specific worker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      From worker 7:\t7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@fetchfrom 7 begin\n",
    "    println(myid());\n",
    "    3+3\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use `@sync` as a blocker to wait for all workers to complete their tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      From worker 7:\tHello\n",
      "      From worker 6:\t class!\n",
      "      From worker 9:\tToday is reverse day!\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "@sync begin\n",
    "    pids = workers()\n",
    "    @spawn (sleep(2); println(\"Today is reverse day!\"))\n",
    "    @spawn (sleep(1); println(\" class!\"))\n",
    "    @spawn println(\"Hello\")\n",
    "end;\n",
    "println(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, now that we understood all that, let's delegate a *complicated* calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RemoteException",
     "evalue": "On worker 9:\nUndefVarError: #complicated_calculation not defined\nStacktrace:\n  [1] deserialize_datatype\n    @ ~/.julia/juliaup/julia-1.8.0+0.x64/share/julia/stdlib/v1.8/Serialization/src/Serialization.jl:1364\n  [2] handle_deserialize\n    @ ~/.julia/juliaup/julia-1.8.0+0.x64/share/julia/stdlib/v1.8/Serialization/src/Serialization.jl:866\n  [3] deserialize\n    @ ~/.julia/juliaup/julia-1.8.0+0.x64/share/julia/stdlib/v1.8/Serialization/src/Serialization.jl:813\n  [4] handle_deserialize\n    @ ~/.julia/juliaup/julia-1.8.0+0.x64/share/julia/stdlib/v1.8/Serialization/src/Serialization.jl:873\n  [5] deserialize\n    @ ~/.julia/juliaup/julia-1.8.0+0.x64/share/julia/stdlib/v1.8/Serialization/src/Serialization.jl:813 [inlined]\n  [6] deserialize_global_from_main\n    @ ~/.julia/juliaup/julia-1.8.0+0.x64/share/julia/stdlib/v1.8/Distributed/src/clusterserialize.jl:160\n  [7] #5\n    @ ~/.julia/juliaup/julia-1.8.0+0.x64/share/julia/stdlib/v1.8/Distributed/src/clusterserialize.jl:72 [inlined]\n  [8] foreach\n    @ ./abstractarray.jl:2774\n  [9] deserialize\n    @ ~/.julia/juliaup/julia-1.8.0+0.x64/share/julia/stdlib/v1.8/Distributed/src/clusterserialize.jl:72\n [10] handle_deserialize\n    @ ~/.julia/juliaup/julia-1.8.0+0.x64/share/julia/stdlib/v1.8/Serialization/src/Serialization.jl:959\n [11] deserialize\n    @ ~/.julia/juliaup/julia-1.8.0+0.x64/share/julia/stdlib/v1.8/Serialization/src/Serialization.jl:813\n [12] handle_deserialize\n    @ ~/.julia/juliaup/julia-1.8.0+0.x64/share/julia/stdlib/v1.8/Serialization/src/Serialization.jl:870\n [13] deserialize\n    @ ~/.julia/juliaup/julia-1.8.0+0.x64/share/julia/stdlib/v1.8/Serialization/src/Serialization.jl:813\n [14] handle_deserialize\n    @ ~/.julia/juliaup/julia-1.8.0+0.x64/share/julia/stdlib/v1.8/Serialization/src/Serialization.jl:873\n [15] deserialize\n    @ ~/.julia/juliaup/julia-1.8.0+0.x64/share/julia/stdlib/v1.8/Serialization/src/Serialization.jl:813 [inlined]\n [16] deserialize_msg\n    @ ~/.julia/juliaup/julia-1.8.0+0.x64/share/julia/stdlib/v1.8/Distributed/src/messages.jl:87\n [17] #invokelatest#2\n    @ ./essentials.jl:729 [inlined]\n [18] invokelatest\n    @ ./essentials.jl:726 [inlined]\n [19] message_handler_loop\n    @ ~/.julia/juliaup/julia-1.8.0+0.x64/share/julia/stdlib/v1.8/Distributed/src/process_messages.jl:176\n [20] process_tcp_streams\n    @ ~/.julia/juliaup/julia-1.8.0+0.x64/share/julia/stdlib/v1.8/Distributed/src/process_messages.jl:133\n [21] #103\n    @ ./task.jl:484",
     "output_type": "error",
     "traceback": [
      "On worker 9:\n",
      "UndefVarError: #complicated_calculation not defined\n",
      "Stacktrace:\n",
      "  [1] deserialize_datatype\n",
      "    @ ~/.julia/juliaup/julia-1.8.0+0.x64/share/julia/stdlib/v1.8/Serialization/src/Serialization.jl:1364\n",
      "  [2] handle_deserialize\n",
      "    @ ~/.julia/juliaup/julia-1.8.0+0.x64/share/julia/stdlib/v1.8/Serialization/src/Serialization.jl:866\n",
      "  [3] deserialize\n",
      "    @ ~/.julia/juliaup/julia-1.8.0+0.x64/share/julia/stdlib/v1.8/Serialization/src/Serialization.jl:813\n",
      "  [4] handle_deserialize\n",
      "    @ ~/.julia/juliaup/julia-1.8.0+0.x64/share/julia/stdlib/v1.8/Serialization/src/Serialization.jl:873\n",
      "  [5] deserialize\n",
      "    @ ~/.julia/juliaup/julia-1.8.0+0.x64/share/julia/stdlib/v1.8/Serialization/src/Serialization.jl:813 [inlined]\n",
      "  [6] deserialize_global_from_main\n",
      "    @ ~/.julia/juliaup/julia-1.8.0+0.x64/share/julia/stdlib/v1.8/Distributed/src/clusterserialize.jl:160\n",
      "  [7] #5\n",
      "    @ ~/.julia/juliaup/julia-1.8.0+0.x64/share/julia/stdlib/v1.8/Distributed/src/clusterserialize.jl:72 [inlined]\n",
      "  [8] foreach\n",
      "    @ ./abstractarray.jl:2774\n",
      "  [9] deserialize\n",
      "    @ ~/.julia/juliaup/julia-1.8.0+0.x64/share/julia/stdlib/v1.8/Distributed/src/clusterserialize.jl:72\n",
      " [10] handle_deserialize\n",
      "    @ ~/.julia/juliaup/julia-1.8.0+0.x64/share/julia/stdlib/v1.8/Serialization/src/Serialization.jl:959\n",
      " [11] deserialize\n",
      "    @ ~/.julia/juliaup/julia-1.8.0+0.x64/share/julia/stdlib/v1.8/Serialization/src/Serialization.jl:813\n",
      " [12] handle_deserialize\n",
      "    @ ~/.julia/juliaup/julia-1.8.0+0.x64/share/julia/stdlib/v1.8/Serialization/src/Serialization.jl:870\n",
      " [13] deserialize\n",
      "    @ ~/.julia/juliaup/julia-1.8.0+0.x64/share/julia/stdlib/v1.8/Serialization/src/Serialization.jl:813\n",
      " [14] handle_deserialize\n",
      "    @ ~/.julia/juliaup/julia-1.8.0+0.x64/share/julia/stdlib/v1.8/Serialization/src/Serialization.jl:873\n",
      " [15] deserialize\n",
      "    @ ~/.julia/juliaup/julia-1.8.0+0.x64/share/julia/stdlib/v1.8/Serialization/src/Serialization.jl:813 [inlined]\n",
      " [16] deserialize_msg\n",
      "    @ ~/.julia/juliaup/julia-1.8.0+0.x64/share/julia/stdlib/v1.8/Distributed/src/messages.jl:87\n",
      " [17] #invokelatest#2\n",
      "    @ ./essentials.jl:729 [inlined]\n",
      " [18] invokelatest\n",
      "    @ ./essentials.jl:726 [inlined]\n",
      " [19] message_handler_loop\n",
      "    @ ~/.julia/juliaup/julia-1.8.0+0.x64/share/julia/stdlib/v1.8/Distributed/src/process_messages.jl:176\n",
      " [20] process_tcp_streams\n",
      "    @ ~/.julia/juliaup/julia-1.8.0+0.x64/share/julia/stdlib/v1.8/Distributed/src/process_messages.jl:133\n",
      " [21] #103\n",
      "    @ ./task.jl:484\n",
      "\n",
      "Stacktrace:\n",
      " [1] remotecall_fetch(::Function, ::Distributed.Worker; kwargs::Base.Pairs{Symbol, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})\n",
      "   @ Distributed ~/.julia/juliaup/julia-1.8.0+0.x64/share/julia/stdlib/v1.8/Distributed/src/remotecall.jl:465\n",
      " [2] remotecall_fetch(::Function, ::Distributed.Worker)\n",
      "   @ Distributed ~/.julia/juliaup/julia-1.8.0+0.x64/share/julia/stdlib/v1.8/Distributed/src/remotecall.jl:454\n",
      " [3] remotecall_fetch(::Function, ::Int64; kwargs::Base.Pairs{Symbol, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})\n",
      "   @ Distributed ~/.julia/juliaup/julia-1.8.0+0.x64/share/julia/stdlib/v1.8/Distributed/src/remotecall.jl:492\n",
      " [4] remotecall_fetch(::Function, ::Int64)\n",
      "   @ Distributed ~/.julia/juliaup/julia-1.8.0+0.x64/share/julia/stdlib/v1.8/Distributed/src/remotecall.jl:492\n",
      " [5] top-level scope\n",
      "   @ ~/repos/JuliaWorkshops/JuliaHLRS22/Day3/2_multiprocessing_and_distributed_computing.ipynb:8"
     ]
    }
   ],
   "source": [
    "using Random\n",
    "\n",
    "function complicated_calculation()\n",
    "    sleep(1) # so complex that it takes a long time :)\n",
    "    randexp(5)\n",
    "end\n",
    "\n",
    "@fetch complicated_calculation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happened?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Every worker is a separate Julia process.** (Think of having multiple Julia REPLs open at once.)\n",
    "\n",
    "We only defined `complicated_calculation()` on the master process. The function doesn't exist on any of the workers yet.\n",
    "\n",
    "The macro `@everywhere` allows us to perform steps on all processes (master and worker). This is particularly useful for loading packages and functions definitions etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "@everywhere begin # execute this block on all workers\n",
    "    using Random\n",
    "    \n",
    "    function complicated_calculation()\n",
    "        sleep(1)\n",
    "        randexp(5) # lives in Random\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5-element Vector{Float64}:\n",
       " 0.824451959101157\n",
       " 1.3304595721548624\n",
       " 0.12687671104385195\n",
       " 1.6127992535773963\n",
       " 1.616419007086614"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@fetch complicated_calculation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data movement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a crucial difference between the following two pieces of code. Can you guess what it is? (without reading on ðŸ˜‰)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "method1 (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function method1()\n",
    "    A = rand(100,100)\n",
    "    B = rand(100,100)\n",
    "    C = @fetch A^2 * B^2\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "method2 (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function method2()\n",
    "    C = @fetch rand(100,100)^2 * rand(100,100)^2\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's benchmark them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  646.503 Î¼s (98 allocations: 237.99 KiB)\n",
      "  414.795 Î¼s (68 allocations: 80.95 KiB)\n"
     ]
    }
   ],
   "source": [
    "using BenchmarkTools\n",
    "@btime method1();\n",
    "@btime method2();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method 1 is slower, because `A` and `B` are created on the master process, transferred to a worker, and squared and multiplied on the worker process before the result is finally transferred back to the master.\n",
    "\n",
    "Method 2, on the other hand, creates, squares, and multiplies the random matrix all on the work process and only submits the result to the master.\n",
    "\n",
    "Hence, `method1` is **transferring 3x as much data** between the master and the worker!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Efficient data movement is crucial for efficient parallel computing!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this toy example, it's rather easy to identify the faster method.\n",
    "\n",
    "In a real program, however, understanding data movement does require more thought and likely some measurement.\n",
    "\n",
    "For example, if the first process needs matrix `A` in a follow-up computation then the first method might be better in this case. Or, if computing `A` is expensive and only the current process has it, then moving it to another process might be unavoidable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Computer latency at a human scale\n",
    "\n",
    "To understand why thinking about data is important it's instructive to look at the time scales involved in data access.\n",
    "\n",
    "<img src=\"../imgs/latency_human_scales.png\" width=900px>\n",
    "\n",
    "(taken from https://www.prowesscorp.com/computer-latency-at-a-human-scale/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Avoid globals (once more)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "myglobal = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "whohas (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function whohas(s::String)\n",
    "    @everywhere begin\n",
    "        var = Symbol($s)\n",
    "        if isdefined(Main, var)\n",
    "            println(\"$var exists.\")\n",
    "        else\n",
    "            println(\"Doesn't exist.\")\n",
    "        end\n",
    "    end\n",
    "    nothing\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "myglobal exists.\n",
      "      From worker 9:\tDoesn't exist.\n",
      "      From worker 7:\tDoesn't exist.\n",
      "      From worker 6:\tDoesn't exist.\n",
      "      From worker 8:\tDoesn't exist.\n"
     ]
    }
   ],
   "source": [
    "whohas(\"myglobal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@fetchfrom 6 myglobal+2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "myglobal exists.\n",
      "      From worker 9:\tDoesn't exist.\n",
      "      From worker 7:\tDoesn't exist.\n",
      "      From worker 8:\tDoesn't exist.\n",
      "      From worker 6:\tmyglobal exists.\n"
     ]
    }
   ],
   "source": [
    "whohas(\"myglobal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Globals get copied to workers and continue to exist as globals even after the call.\n",
    "\n",
    "This could lead to **memory accumulation** if many globals are used (just as it would in a single Julia session).\n",
    "\n",
    "It's better to avoid them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explicit data movement: `Channel` and `RemoteChannel`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement communication between tasks. Functions: `put!`, `take!`, `fetch`, `isready` and `wait`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Channel{Int64}(5) (empty)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ch = Channel{Int}(5) # a channel that can hold up to 5 integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "false"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "isready(ch) # something in the channel?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "put!(ch, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "false"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "isready(ch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "3+3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "fetch(ch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "take!(ch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "false"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "isready(ch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "put!(ch, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fetch(ch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "take!(ch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Be careful**, `take!` and `put!` are blocking if the channel is empty or full!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "false"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isready(ch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take!(ch) if we execute this, while isready(ch) == false, the current Julia session will hang."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `RemoteChannel`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* A `Channel` is local to a process. Worker 2 cannot directly refer to a `Channel` on worker 3 and vice-versa.\n",
    "\n",
    "\n",
    "* A `RemoteChannel`, however, can put and take values across workers. A `RemoteChannel` can be thought of as a handle to a `Channel`.\n",
    "\n",
    "\n",
    "* Any process with a reference to a `RemoteChannel` can put and take items from the channel. Data is automatically sent to (or retrieved from) the process a `RemoteChannel` is associated with.\n",
    "\n",
    "\n",
    "* The process id, pid, associated with a `RemoteChannel` identifies the process where the backing store, i.e., the backing Channel exists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nworkers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "addprocs(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RemoteChannel{Channel{Int64}}(1, 1, 8804)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function do_something()\n",
    "    rc = RemoteChannel(()->Channel{Int}(10)) # lives on the master\n",
    "    @sync for p in workers()\n",
    "        @spawnat p put!(rc, myid())\n",
    "    end\n",
    "    rc\n",
    "end\n",
    "\n",
    "r = do_something()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "isready(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "take!(r) = 9\n",
      "take!(r) = 8\n",
      "take!(r) = 7\n",
      "take!(r) = 6\n"
     ]
    }
   ],
   "source": [
    "while isready(r)\n",
    "    @show take!(r)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ecosystem also contains a couple of tools, that make data transfer even simpler. See for example [ParallelDataTransfer.jl](https://github.com/ChrisRackauckas/ParallelDataTransfer.jl/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## High-level tools: `@distributed` and `pmap`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far we have seen some of the fundamental building blocks for distributed computing in Julia. However, in practice, one wants to think as little as possible about how to distribute the work and explicitly spawn tasks.\n",
    "\n",
    "Fortunately, many useful parallel computations do not require (much) data movement at all. A common example is a direct Monte Carlo simulation, where multiple processes can handle independent simulation trials simultaneously. (We'll get to that later in the exercises!)\n",
    "\n",
    "Julia provides **high-level convenience** tools to\n",
    " * parallelize loops ([**`@distributed`**](https://docs.julialang.org/en/v1/stdlib/Distributed/#Distributed.@distributed)) and\n",
    " * apply a function to all elements of a collection ([**`pmap`**](https://docs.julialang.org/en/v1/stdlib/Distributed/#Distributed.pmap))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Distributed loops (`@distributed`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "â”Œ Warning: rmprocs: process 1 not removed\n",
      "â”” @ Distributed /Users/julia/.julia/scratchspaces/a66863c6-20e8-4ff4-8a62-49f30b1f605e/agent-cache/default-macmini-x64-6.0/build/default-macmini-x64-6-0/julialang/julia-release-1-dot-8/usr/share/julia/stdlib/v1.8/Distributed/src/cluster.jl:1048\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Distributed, BenchmarkTools; rmprocs(workers()); addprocs(4); nworkers()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example: Reduction\n",
    "\n",
    "Task: Counting heads in a series of coin tosses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  322.219 ms (0 allocations: 0 bytes)\n"
     ]
    }
   ],
   "source": [
    "function count_heads_loop(n)\n",
    "    c = 0\n",
    "    for i = 1:n\n",
    "        c += rand(Bool)\n",
    "    end\n",
    "    return c\n",
    "end\n",
    "\n",
    "N = 200_000_000\n",
    "@btime count_heads_loop($N);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that these kinds of computations are called **reductions** (with `+` being the **reducer function**)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  326.941 ms (0 allocations: 0 bytes)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "100004576"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_heads_reduce(n) = mapreduce(i -> rand(Bool), +, 1:n)\n",
    "@btime count_heads_reduce($N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count_heads_distributed_loop (generic function with 1 method)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function count_heads_distributed_loop(n)\n",
    "    c = @distributed (+) for i in 1:n\n",
    "        Int(rand(Bool))\n",
    "    end\n",
    "    return c\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  81.147 ms (302 allocations: 12.55 KiB)\n"
     ]
    }
   ],
   "source": [
    "@btime count_heads_distributed_loop($N);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distributed version is about **4x faster**, which is all we could hope for."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With `@distributed` the work is **evenly distributed** between the workers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      From worker 3:\t0\n",
      "      From worker 2:\t0\n",
      "      From worker 4:\t0\n",
      "      From worker 5:\t1\n",
      "      From worker 5:\t0\n",
      "      From worker 3:\t1\n",
      "      From worker 2:\t1\n",
      "      From worker 4:\t0\n"
     ]
    }
   ],
   "source": [
    "function count_heads_distributed_verbose(n)\n",
    "    c = @distributed (+) for i in 1:n\n",
    "        x = Int(rand(Bool))\n",
    "        println(x);\n",
    "        x\n",
    "    end\n",
    "    c\n",
    "end\n",
    "\n",
    "count_heads_distributed_verbose(8);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, by using `@distributed` we let Julia decide how to split up the work and can't control it ourselves."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A common mistake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "function g(n)\n",
    "    a = 0\n",
    "    @distributed (+) for i in 1:n\n",
    "        a += 1\n",
    "    end\n",
    "    a\n",
    "end\n",
    "\n",
    "a = g(10);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do you expect the value of `a` to be?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example: `SharedArray`s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apart from `@distributed (reducer) ...` there also is a `@distributed for ...` form. The latter is **non-blocking** and returns a `Task`. (You can think of it as a distributed version of `@spawn` for all the iterations.)\n",
    "\n",
    "However, since the loop body will be executed on different processes, one must be careful to operate on data structures that are available on all processes (similar to the mistake highlighted above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "square_broken (generic function with 1 method)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function square_broken()\n",
    "    A = collect(1:10)\n",
    "    @sync @distributed for i in eachindex(A)\n",
    "        A[i] = A[i]^2\n",
    "    end\n",
    "    return A\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10-element Vector{Int64}:\n",
       "  1\n",
       "  2\n",
       "  3\n",
       "  4\n",
       "  5\n",
       "  6\n",
       "  7\n",
       "  8\n",
       "  9\n",
       " 10"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "square_broken()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To actually make all processes operate on the same array, one can use a `SharedArray`. For this to work, the **processes need to live on the same host**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "@everywhere using SharedArrays # must be loaded everywhere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3Ã—2 Matrix{Float64}:\n",
       " 0.538336  0.0201671\n",
       " 0.212669  0.888775\n",
       " 0.405967  0.313966"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = rand(3,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3Ã—2 SharedMatrix{Float64}:\n",
       " 0.538336  0.0201671\n",
       " 0.212669  0.888775\n",
       " 0.405967  0.313966"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S = SharedArray(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  229.457 ms (508 allocations: 15.31 KiB)\n",
      "  58.816 ms (574 allocations: 26.09 KiB)\n"
     ]
    }
   ],
   "source": [
    "function square!(X)\n",
    "    for i in eachindex(X)\n",
    "        sleep(0.001) # mimicing some computational cost\n",
    "        X[i] = X[i]^2\n",
    "    end\n",
    "end\n",
    "\n",
    "function square_distributed!(X)\n",
    "    @sync @distributed for i in eachindex(X)\n",
    "        sleep(0.001) # mimicing some computational cost\n",
    "        X[i] = X[i]^2\n",
    "    end\n",
    "end\n",
    "\n",
    "A = rand(10,10)\n",
    "S = SharedArray(A)\n",
    "\n",
    "@btime square!(A);\n",
    "@btime square_distributed!($S);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parallel map: `pmap`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `square!` functions above are typical `map` operations where a function `f` is applied to all elements of a collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10-element Vector{Int64}:\n",
       "   1\n",
       "   4\n",
       "   9\n",
       "  16\n",
       "  25\n",
       "  36\n",
       "  49\n",
       "  64\n",
       "  81\n",
       " 100"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map(x->x^2, 1:10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Such a pattern can be parallelized in Julia via the high-level function `pmap` (\"parallel map\")."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example: Singular values of multiple matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "â”Œ Warning: rmprocs: process 1 not removed\n",
      "â”” @ Distributed /Users/julia/.julia/scratchspaces/a66863c6-20e8-4ff4-8a62-49f30b1f605e/agent-cache/default-macmini-x64-6.0/build/default-macmini-x64-6-0/julialang/julia-release-1-dot-8/usr/share/julia/stdlib/v1.8/Distributed/src/cluster.jl:1048\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Distributed, BenchmarkTools; rmprocs(workers()); addprocs(4); nworkers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "@everywhere using LinearAlgebra\n",
    "\n",
    "M = Matrix{Float64}[rand(200,200) for i = 1:10];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2-element Vector{Float64}:\n",
       " 1.567295814264191\n",
       " 0.05638577289583601"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svdvals(rand(2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10-element Vector{Vector{Float64}}:\n",
       " [99.6378139397788, 7.953440321631967, 7.89163500923745, 7.794278173305783, 7.601075754241636, 7.532778071932169, 7.495234488220123, 7.37095663387068, 7.290094762057224, 7.24038507051588  â€¦  0.2577599248490027, 0.24168950803061742, 0.19460642318981866, 0.17353097393282843, 0.16126794350742069, 0.14854630524019563, 0.12259385086810454, 0.05567251849314098, 0.028137990789380413, 0.004019967434655436]\n",
       " [99.97491934942695, 8.136311451491352, 7.9045359058287215, 7.847918834879346, 7.740466115796857, 7.596100441052067, 7.5252931307955215, 7.422301114226823, 7.278904160097977, 7.154623741055865  â€¦  0.28764020300987836, 0.23672411802597415, 0.22617107993934113, 0.17734897787737702, 0.1640599747511493, 0.10738905216166718, 0.09961959432527073, 0.06895712121746422, 0.04113860155120967, 0.019051549507549954]\n",
       " [100.54302411474777, 8.066270701024377, 7.816097994710581, 7.740430872496169, 7.672445958918696, 7.601081020110799, 7.497556443647828, 7.40728999820195, 7.363670644626484, 7.290570869423972  â€¦  0.2846857353998257, 0.27744123697375433, 0.2537055156390425, 0.22689451190628174, 0.19597321215411842, 0.14419296356687228, 0.1115109175268925, 0.06820196639659677, 0.04742671076527815, 0.023635978226522487]\n",
       " [99.58243596097165, 8.004910400826047, 7.9721484717178095, 7.792529594720834, 7.634659960527464, 7.545778203563315, 7.457588767238603, 7.442119739280718, 7.395508734392731, 7.24961271958506  â€¦  0.2801424339471566, 0.2670581026297794, 0.2512027462272705, 0.23293235709788834, 0.21338263803456553, 0.15297172186602997, 0.1410142828056575, 0.11085563322693152, 0.06256865412825376, 0.02632744045012696]\n",
       " [99.89884691634364, 8.094580421360472, 7.944129980534577, 7.737781829500266, 7.681431916366467, 7.570640744137934, 7.494654587731072, 7.446857165444672, 7.3494265982111555, 7.291459331353473  â€¦  0.32269990473716903, 0.28249843748539033, 0.25204551476399845, 0.20138780856854055, 0.19499715865455794, 0.12416017413952987, 0.09526731545052342, 0.08953175961572046, 0.014990492031484694, 0.006546832093615505]\n",
       " [99.81672933859566, 7.893980343176923, 7.796226928690283, 7.633490742182489, 7.587526387318584, 7.536160724012713, 7.4364698518567405, 7.3652324085176355, 7.317736464494491, 7.185240705933286  â€¦  0.30202786708631346, 0.2733162564272133, 0.2648804983906084, 0.20386771648876953, 0.19530276860150692, 0.1763317769146818, 0.13994813608680728, 0.08135793073375513, 0.05800638688571411, 0.0306962665477805]\n",
       " [100.24026414868155, 8.060482479987794, 7.969108559390491, 7.808525379274797, 7.716121871607939, 7.597224447936187, 7.509695173370333, 7.443348446619998, 7.353478290903579, 7.2549142908795865  â€¦  0.3218844912385695, 0.2551194442819301, 0.2240218450206685, 0.20633569277177025, 0.17219244516323884, 0.15057540404139044, 0.09721518414888232, 0.08444731853292543, 0.03195208838842195, 0.008740365948755347]\n",
       " [100.616652088284, 7.958853581255575, 7.8813576676639805, 7.805332528972116, 7.591628479964184, 7.506832560246581, 7.44934445198817, 7.3830453112652945, 7.335209879632607, 7.189896232442807  â€¦  0.2937443038945283, 0.2641843329282119, 0.23401058868061042, 0.20514488589041163, 0.16150782626347626, 0.14332103551633832, 0.10384868090578556, 0.09401529286406837, 0.03188282014807493, 0.008880896012845826]\n",
       " [100.0650867721194, 7.99358734529093, 7.782501367731442, 7.6690997614855645, 7.6347646596634124, 7.601800533672365, 7.419026940111492, 7.366715992486937, 7.348445229474688, 7.253861733166479  â€¦  0.2965466942208024, 0.26175651064634137, 0.22553893050750012, 0.21378766988037523, 0.1762794823003659, 0.16774651849464015, 0.13107555971736715, 0.09585272847531748, 0.05219703196934568, 0.033391673660421804]\n",
       " [99.87230426326926, 8.046025549602987, 7.83621641079322, 7.811890801804334, 7.707461993838727, 7.6041783744325855, 7.509980637476716, 7.476302763447307, 7.2844857672355605, 7.250984142351761  â€¦  0.30733881318881845, 0.27096787321190036, 0.25031036971790815, 0.2143794231836765, 0.17770224214290126, 0.1404052643398673, 0.09840870692937818, 0.06977001934829943, 0.05634024678179627, 0.003323596550606554]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map(svdvals, M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10-element Vector{Vector{Float64}}:\n",
       " [99.6378139397788, 7.953440321631967, 7.891635009237456, 7.794278173305781, 7.601075754241633, 7.532778071932167, 7.495234488220115, 7.370956633870673, 7.290094762057221, 7.240385070515878  â€¦  0.2577599248490024, 0.2416895080306173, 0.1946064231898194, 0.17353097393282851, 0.1612679435074207, 0.14854630524019552, 0.12259385086810495, 0.055672518493140664, 0.02813799078937989, 0.004019967434655434]\n",
       " [99.97491934942695, 8.13631145149135, 7.9045359058287215, 7.847918834879345, 7.740466115796855, 7.5961004410520765, 7.525293130795524, 7.422301114226826, 7.27890416009798, 7.154623741055871  â€¦  0.287640203009877, 0.236724118025973, 0.22617107993934096, 0.17734897787737688, 0.16405997475114945, 0.10738905216166734, 0.09961959432527073, 0.06895712121746406, 0.041138601551209464, 0.019051549507549753]\n",
       " [100.54302411474775, 8.06627070102437, 7.816097994710592, 7.740430872496167, 7.672445958918696, 7.6010810201107954, 7.497556443647827, 7.407289998201957, 7.363670644626478, 7.2905708694239815  â€¦  0.28468573539982417, 0.27744123697375483, 0.25370551563904337, 0.2268945119062822, 0.19597321215411834, 0.14419296356687225, 0.11151091752689266, 0.06820196639659651, 0.04742671076527789, 0.02363597822652312]\n",
       " [99.58243596097165, 8.004910400826049, 7.972148471717815, 7.7925295947208255, 7.634659960527464, 7.545778203563302, 7.457588767238604, 7.44211973928072, 7.3955087343927275, 7.249612719585064  â€¦  0.2801424339471558, 0.26705810262978047, 0.25120274622727, 0.23293235709788826, 0.2133826380345659, 0.15297172186603059, 0.14101428280565753, 0.11085563322693247, 0.06256865412825334, 0.026327440450126714]\n",
       " [99.89884691634364, 8.094580421360472, 7.944129980534571, 7.737781829500272, 7.681431916366467, 7.570640744137935, 7.494654587731076, 7.44685716544466, 7.349426598211152, 7.291459331353476  â€¦  0.32269990473716936, 0.2824984374853899, 0.25204551476399767, 0.20138780856853944, 0.19499715865455824, 0.12416017413953066, 0.09526731545052379, 0.0895317596157204, 0.01499049203148507, 0.006546832093615426]\n",
       " [99.81672933859566, 7.89398034317692, 7.796226928690296, 7.633490742182495, 7.587526387318595, 7.536160724012709, 7.436469851856725, 7.365232408517641, 7.317736464494481, 7.1852407059332934  â€¦  0.30202786708631363, 0.27331625642721374, 0.26488049839060906, 0.2038677164887701, 0.1953027686015071, 0.1763317769146825, 0.13994813608680706, 0.08135793073375498, 0.05800638688571382, 0.03069626654778074]\n",
       " [100.24026414868155, 8.060482479987792, 7.969108559390478, 7.808525379274794, 7.71612187160795, 7.597224447936162, 7.509695173370328, 7.443348446619993, 7.353478290903576, 7.254914290879585  â€¦  0.32188449123856927, 0.2551194442819311, 0.22402184502066827, 0.206335692771771, 0.17219244516323887, 0.15057540404139, 0.09721518414888211, 0.08444731853292575, 0.03195208838842144, 0.008740365948755435]\n",
       " [100.61665208828398, 7.958853581255568, 7.881357667663985, 7.805332528972114, 7.591628479964174, 7.506832560246584, 7.449344451988165, 7.383045311265291, 7.335209879632605, 7.189896232442805  â€¦  0.29374430389452877, 0.2641843329282122, 0.23401058868061067, 0.20514488589041135, 0.1615078262634758, 0.14332103551633796, 0.1038486809057858, 0.09401529286406912, 0.03188282014807431, 0.008880896012845429]\n",
       " [100.0650867721194, 7.993587345290926, 7.782501367731446, 7.669099761485561, 7.63476465966341, 7.60180053367236, 7.4190269401114906, 7.366715992486935, 7.348445229474685, 7.253861733166479  â€¦  0.29654669422080154, 0.2617565106463406, 0.2255389305075004, 0.2137876698803754, 0.17627948230036555, 0.16774651849463978, 0.13107555971736723, 0.09585272847531708, 0.052197031969345414, 0.03339167366042224]\n",
       " [99.87230426326926, 8.046025549602987, 7.83621641079322, 7.811890801804342, 7.707461993838722, 7.6041783744325935, 7.509980637476721, 7.476302763447309, 7.2844857672355605, 7.250984142351755  â€¦  0.30733881318881895, 0.27096787321190063, 0.2503103697179071, 0.21437942318367653, 0.1777022421429011, 0.14040526433986647, 0.09840870692937842, 0.0697700193483001, 0.05634024678179612, 0.0033235965506064336]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pmap(svdvals, M)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check that this indeed utilized multiple workers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      From worker 6:\t6\n",
      "      From worker 9:\t9\n",
      "      From worker 8:\t8\n",
      "      From worker 7:\t7\n",
      "      From worker 6:\t6\n",
      "      From worker 9:\t9\n",
      "      From worker 8:\t8\n",
      "      From worker 7:\t7\n",
      "      From worker 6:\t6\n",
      "      From worker 9:\t9\n"
     ]
    }
   ],
   "source": [
    "pmap(M) do m\n",
    "    println(myid());\n",
    "    svdvals(m)\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  54.712 ms (81 allocations: 4.22 MiB)\n",
      "  15.392 ms (519 allocations: 37.59 KiB)\n"
     ]
    }
   ],
   "source": [
    "@btime map($svdvals, $M);\n",
    "@btime pmap($svdvals, $M);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When to choose which? (`@distributed` vs `pmap`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Julia's `pmap` is designed for the case where\n",
    "\n",
    "* one wants to apply **a function to a collection**,\n",
    "* each function call does a **larger amount of work**, and/or\n",
    "* the **workload is non-uniform** (load-balancing).\n",
    "\n",
    "On the other hand, `@distributed` is good for\n",
    "\n",
    "* **reductions**, like sums, where\n",
    "* **each iteration may be tiny**, i.e. perhaps only summing two numbers, and/or\n",
    "* each iteration **takes about the same time** (uniform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## High-level array abstractions: [DistributedArrays.jl](https://github.com/JuliaParallel/DistributedArrays.jl)\n",
    "\n",
    "In a `DArray`, each process has local access to just a chunk of the data, and no two processes share the same chunk. Processes can be on different hosts.\n",
    "\n",
    "Distributed arrays are for example useful if\n",
    "\n",
    "* Expensive calculations should be performed in parallel on parts of the array on different hosts.\n",
    "* The data doesn't fit into the local machines memory (i.e. loading big files in parallel)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Distributed, BenchmarkTools; rmprocs(workers());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element Vector{Int64}:\n",
       " 18\n",
       " 19\n",
       " 20\n",
       " 21"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make sure that all workers use the same Julia environment\n",
    "addprocs(4; exeflags=\"--project\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base.active_project() = \"/Users/crstnbr/repos/JuliaWorkshops/JuliaHLRS22/Project.toml\"\n",
      "      From worker 18:\tBase.active_project() = \"/Users/crstnbr/repos/JuliaWorkshops/JuliaHLRS22/Project.toml\"\n",
      "      From worker 20:\tBase.active_project() = \"/Users/crstnbr/repos/JuliaWorkshops/JuliaHLRS22/Project.toml\"\n",
      "      From worker 19:\tBase.active_project() = \"/Users/crstnbr/repos/JuliaWorkshops/JuliaHLRS22/Project.toml\"\n",
      "      From worker 21:\tBase.active_project() = \"/Users/crstnbr/repos/JuliaWorkshops/JuliaHLRS22/Project.toml\"\n"
     ]
    }
   ],
   "source": [
    "# check\n",
    "@everywhere @show Base.active_project()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "@everywhere using DistributedArrays, LinearAlgebra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = Matrix{Float64}[rand(200,200) for i = 1:10];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10-element DArray{Matrix{Float64}, 1, Vector{Matrix{Float64}}}:\n",
       " [0.5237691826804336 0.19225096693554433 â€¦ 0.5090894478257938 0.4291709018910801; 0.784076589614852 0.9465938731556683 â€¦ 0.8866692692147827 0.23078868748940606; â€¦ ; 0.9301320539467216 0.18002927673847213 â€¦ 0.20712165241145475 0.38691641344246575; 0.014943227868830067 0.9594987864892671 â€¦ 0.1927723985879496 0.3766169725992071]\n",
       " [0.8136404329733 0.05781792976522582 â€¦ 0.2050434642570984 0.8446583617836078; 0.7404851199722592 0.515868618368856 â€¦ 0.3602494061828969 0.10575579930925216; â€¦ ; 0.41589684599812193 0.4130817814398151 â€¦ 0.37854001243504165 0.08852822867485644; 0.6534747412823856 0.6649896285915354 â€¦ 0.18282864782699548 0.5905227171779412]\n",
       " [0.7030968713815184 0.8070261550611442 â€¦ 0.5529152789870686 0.3656795854446987; 0.683572997346583 0.7639500141177592 â€¦ 0.8344616585922441 0.7344088914926489; â€¦ ; 0.5898838278833306 0.1080725735105097 â€¦ 0.7600821379000914 0.32532611977604753; 0.0639964176175869 0.2989436703831376 â€¦ 0.783823464383249 0.2144418884285717]\n",
       " [0.7298524790944769 0.5578237862925786 â€¦ 0.5443753804657386 0.639726857068898; 0.9358219325984957 0.4109752200045964 â€¦ 0.09310938184748829 0.7691295424653946; â€¦ ; 0.3685687358530002 0.8122284010401609 â€¦ 0.2841963712356571 0.8320175232860927; 0.9770315388030711 0.8469637848468632 â€¦ 0.989803190798628 0.9552445130284445]\n",
       " [0.17558701606393834 0.7496312810476363 â€¦ 0.23124047278906523 0.3348439855652553; 0.9310541830826508 0.8194445191440144 â€¦ 0.9235972584923953 0.731330861990937; â€¦ ; 0.4876595481213224 0.4544012625485101 â€¦ 0.9469688764313117 0.39083345635393674; 0.595961887369023 0.2526560219999803 â€¦ 0.841221075489284 0.6570826854102401]\n",
       " [0.7886767283340647 0.660878600821197 â€¦ 0.1262291746886136 0.9714580304976514; 0.8459930731922014 0.6488434114951809 â€¦ 0.6832352728844192 0.2865594730351172; â€¦ ; 0.6411221060257254 0.7081047154805058 â€¦ 0.491245136568388 0.523126297272805; 0.2425453037814712 0.6624742830563441 â€¦ 0.8434404274689923 0.750376824330942]\n",
       " [0.8565163707870205 0.7837146092846669 â€¦ 0.08125874032464375 0.44873011151232256; 0.7732283016515834 0.9361368198805887 â€¦ 0.24615653082242206 0.07797466806253006; â€¦ ; 0.03667128233815231 0.08444618942704951 â€¦ 0.6114142534486495 0.4327160493267851; 0.08841735332062806 0.37135885635656196 â€¦ 0.9860892168325867 0.876270547279856]\n",
       " [0.5375174296744787 0.3108727683780593 â€¦ 0.8927606422856541 0.8673511752629114; 0.7464000791782872 0.2399335273848029 â€¦ 0.707064030269211 0.3117828593599803; â€¦ ; 0.4626388288504024 0.6120879813726193 â€¦ 0.3701584939245397 0.351789104928408; 0.27426299640193097 0.0484482648972413 â€¦ 0.7578939099235222 0.547481500906397]\n",
       " [0.27744691459313475 0.38966543462594727 â€¦ 0.1286250810936046 0.44630921657989; 0.7737896110281983 0.23050900009798803 â€¦ 0.5851121106093992 0.7016462341885957; â€¦ ; 0.17823160267640215 0.424121936206853 â€¦ 0.3392129232470439 0.35993039662330906; 0.22408273299781722 0.5698444405663737 â€¦ 0.5479956809708995 0.8005438468763794]\n",
       " [0.04637180500301785 0.9999052794604918 â€¦ 0.9318376129691741 0.1605113806084455; 0.48410867987844997 0.5658799057507395 â€¦ 0.9669722761298135 0.6871997788191946; â€¦ ; 0.822207164414661 0.6420778217502066 â€¦ 0.4117690801470596 0.2512556329817306; 0.8220758980857309 0.9435799444028627 â€¦ 0.8347533100808022 0.607313929375617]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D = distribute(M)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which workers hold parts of D?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element Vector{Int64}:\n",
       " 18\n",
       " 19\n",
       " 20\n",
       " 21"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "procs(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element Vector{Int64}:\n",
       " 18\n",
       " 19\n",
       " 20\n",
       " 21"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workers()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which parts do they hold?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Matrix{Float64}[]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "localpart(D) # the master doesn't hold anything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1:3,)\n",
      "(4:6,)\n",
      "(7:8,)\n",
      "(9:10,)\n"
     ]
    }
   ],
   "source": [
    "# Which parts do they hold?\n",
    "for p in workers()\n",
    "    println(@fetchfrom p DistributedArrays.localindices(D))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  52.903 ms (81 allocations: 4.22 MiB)\n",
      "  13.749 ms (577 allocations: 30.42 KiB)\n"
     ]
    }
   ],
   "source": [
    "@btime map($svdvals, $M);\n",
    "@btime map($svdvals, $D);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  15.324 ms (518 allocations: 37.33 KiB)\n"
     ]
    }
   ],
   "source": [
    "@btime pmap($svdvals, $M);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Actual* distributed computing: Comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating workers on other machines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far we have worked with multiple process on the same system, because we simply used `addprocs(::Integer)`. To put worker processes on other machines, e.g. nodes of a cluster, we need to modify the initial `addprocs` call appropriately.\n",
    "\n",
    "In Julia, starting worker processes is handled by [ClusterManagers](https://docs.julialang.org/en/v1/manual/distributed-computing/#ClusterManagers).\n",
    "\n",
    "* The default one is `LocalManager`. It is automatically used when running `addprocs(i::Integer)` and we have implicitly used it already.\n",
    "* Another important one is `SSHManager`. It is automatically used when running `addprocs(hostnames::Array)`, e.g. `addprocs([\"node123\", \"node456\"])`. The only requirement is a **passwordless ssh access** to all specified hosts.\n",
    "* Cluster managers for SLURM, PBS, and others are provided in [ClusterManagers.jl](https://github.com/JuliaParallel/ClusterManagers.jl). For SLURM, this will make `addprocs` use `srun` under the hood."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Demonstrate in terminal from thp node*\n",
    "\n",
    "```julia\n",
    "using Distributed\n",
    "\n",
    "addprocs([\"l93\", \"l94\"])\n",
    "\n",
    "@everywhere println(gethostname())\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One can also start multiple processes on different machines:\n",
    "```julia\n",
    "addprocs([(\"node123\", 2), (\"node456\", 3)]) # starts 2 workers on node123 and 3 workers on node456\n",
    "\n",
    "# Use :auto to start as many processes as CPU threads are available\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Be aware of different paths:**\n",
    "* By default, `addprocs` expects to find the julia executable on the remote machines under the same path as on the host (master).\n",
    "* It will also try to `cd` to the same folder (set the working directory).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see from `?addprocs`, `addprocs` takes a bunch of keyword arguments, two of which are of particular importance in this regard:\n",
    "\n",
    "* `dir`: working directory for the worker processes\n",
    "* `exename`: path to julia executable (potentially augmented with pre-commands) for the worker processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "â”Œ Warning: rmprocs: process 1 not removed\n",
      "â”” @ Distributed /Users/julia/.julia/scratchspaces/a66863c6-20e8-4ff4-8a62-49f30b1f605e/agent-cache/default-macmini-x64-6.0/build/default-macmini-x64-6-0/julialang/julia-release-1-dot-8/usr/share/julia/stdlib/v1.8/Distributed/src/cluster.jl:1048\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Task (done) @0x000000011c56b9d0"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cleanup\n",
    "rmprocs(workers())"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Julia 1.8.0",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

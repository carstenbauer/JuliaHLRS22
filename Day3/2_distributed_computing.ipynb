{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distributed Computing: `Distributed` standard library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What**\n",
    "* **single Julia process -> multiple Julia processes** that coordinate to perform certain computations\n",
    "\n",
    "**Why**\n",
    "* Scaling things up: run computations on multiple CPU cores, potentially even on different machines, e.g. nodes of a supercomputer or a local cluster of desktop machines.\n",
    "* Effectively increase your memory: process a large dataset, which wouldn't fit into local memory, in parallel across multiple machines with separate dedicated RAM.\n",
    "\n",
    "**Julia provides two fundamental implementations and paradigms**\n",
    "* Julia's built-in [`Distributed` standard library](https://docs.julialang.org/en/v1/stdlib/Distributed/)\n",
    "  * master-worker model\n",
    "* [Message Passing Interface (MPI)](https://www.mpi-forum.org/) through [MPI.jl](https://github.com/JuliaParallel/MPI.jl)\n",
    "  * Single Program Multiple Data (SPMD)\n",
    "  \n",
    "The focus of this notebook is on the **`Distributed` standard library.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Distributed` standard library\n",
    "\n",
    "Julia's `Distributed` follows a master-worker paradigm for its native distributed parallelism: **One master process coordinates all the worker processes, which perform the actual computations.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Distributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nprocs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nworkers() # the master is considered a worker as long as there are no real workers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To increase the number of workers, i.e. Julia processes, from within a Julia session we can dynamically call **`addprocs`**.\n",
    "\n",
    "Alternatively, when starting Julia from the command line, one can use the `-p` option up front. Example,\n",
    "\n",
    "```\n",
    "julia -p 4\n",
    "```\n",
    "\n",
    "will start Julia with 5 processes, 1 master and 4 workers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "addprocs(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every process has a Julia internal `pid` (process id). The master is always 1. You can get the workers pids from `workers()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workers()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the 4 worker's pids aren't necessarily 2, 3, 4 and 5 and one shouldn't rely on those literal values. Let's remove the processes and add them once more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmprocs(workers())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nworkers() # only the master is left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "addprocs(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workers()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One master to rule them all - `@spawn`, `@spawnat`, `@fetch`, `@fetchfrom`, `@everywhere`..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To execute commands and start computations on workers we can use the following macros\n",
    "\n",
    "* `@spawn`: run a command or a code block on any worker and return a `Future` to it's result. It's basically a version of `@async` for remote processes.\n",
    "* `@spawnat`: same as `@spawn` but one can choose a specific worker by providing its pid."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example:** Let's say we would like to generate a random matrix on one of the workers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@spawn 3+3 # similar to @async"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = @spawn 3+3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fetch(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the combination of spawning at fetching is so common, there is `@fetch` which combines them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@fetch 3+3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@fetch rand(3,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which worker did the work?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@fetch begin\n",
    "    println(myid());\n",
    "    3+3\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `@spawnat` and `@fetchfrom` we can delegate the work to a specific worker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@fetchfrom 7 begin\n",
    "    println(myid());\n",
    "    3+3\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use `@sync` as a blocker to wait for all workers to complete their tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@sync begin\n",
    "    pids = workers()\n",
    "    @spawn (sleep(2); println(\"Today is reverse day!\"))\n",
    "    @spawn (sleep(1); println(\" class!\"))\n",
    "    @spawn println(\"Hello\")\n",
    "end;\n",
    "println(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, now that we understood all that, let's delegate a *complicated* calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "using Random\n",
    "\n",
    "function complicated_calculation()\n",
    "    sleep(1) # so complex that it takes a long time :)\n",
    "    randexp(5)\n",
    "end\n",
    "\n",
    "@fetch complicated_calculation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happened?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Every worker is a separate Julia process.** (Think of having multiple Julia REPLs open at once.)\n",
    "\n",
    "We only defined `complicated_calculation()` on the master process. The function doesn't exist on any of the workers yet.\n",
    "\n",
    "The macro `@everywhere` allows us to perform steps on all processes (master and worker). This is particularly useful for loading packages and functions definitions etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@everywhere begin # execute this block on all workers\n",
    "    using Random\n",
    "    \n",
    "    function complicated_calculation()\n",
    "        sleep(1)\n",
    "        randexp(5) # lives in Random\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@fetch complicated_calculation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data movement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a crucial difference between the following two pieces of code. Can you guess what it is? (without reading on ðŸ˜‰)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function method1()\n",
    "    A = rand(100,100)\n",
    "    B = rand(100,100)\n",
    "    C = @fetch A^2 * B^2\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function method2()\n",
    "    C = @fetch rand(100,100)^2 * rand(100,100)^2\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's benchmark them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using BenchmarkTools\n",
    "@btime method1();\n",
    "@btime method2();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method 1 is slower, because `A` and `B` are created on the master process, transferred to a worker, and squared and multiplied on the worker process before the result is finally transferred back to the master.\n",
    "\n",
    "Method 2, on the other hand, creates, squares, and multiplies the random matrix all on the work process and only submits the result to the master.\n",
    "\n",
    "Hence, `method1` is **transferring 3x as much data** between the master and the worker!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Efficient data movement is crucial for efficient parallel computing!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this toy example, it's rather easy to identify the faster method.\n",
    "\n",
    "In a real program, however, understanding data movement does require more thought and likely some measurement.\n",
    "\n",
    "For example, if the first process needs matrix `A` in a follow-up computation then the first method might be better in this case. Or, if computing `A` is expensive and only the current process has it, then moving it to another process might be unavoidable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Computer latency at a human scale\n",
    "\n",
    "To understand why thinking about data is important it's instructive to look at the time scales involved in data access.\n",
    "\n",
    "<img src=\"../imgs/latency_human_scales.png\" width=900px>\n",
    "\n",
    "(taken from https://www.prowesscorp.com/computer-latency-at-a-human-scale/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Avoid globals (once more)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myglobal = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function whohas(s::String)\n",
    "    @everywhere begin\n",
    "        var = Symbol($s)\n",
    "        if isdefined(Main, var)\n",
    "            println(\"$var exists.\")\n",
    "        else\n",
    "            println(\"Doesn't exist.\")\n",
    "        end\n",
    "    end\n",
    "    nothing\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whohas(\"myglobal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@fetchfrom 6 myglobal+2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whohas(\"myglobal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Globals get copied to workers and continue to exist as globals even after the call.\n",
    "\n",
    "This could lead to **memory accumulation** if many globals are used (just as it would in a single Julia session).\n",
    "\n",
    "It's better to avoid them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explicit data movement: `Channel` and `RemoteChannel`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement communication between tasks. Functions: `put!`, `take!`, `fetch`, `isready` and `wait`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ch = Channel{Int}(5) # a channel that can hold up to 5 integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isready(ch) # something in the channel?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "put!(ch, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isready(ch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "3+3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fetch(ch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "take!(ch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isready(ch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "put!(ch, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fetch(ch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "take!(ch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Be careful**, `take!` and `put!` are blocking if the channel is empty or full!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isready(ch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take!(ch) if we execute this, while isready(ch) == false, the current Julia session will hang."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `RemoteChannel`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* A `Channel` is local to a process. Worker 2 cannot directly refer to a `Channel` on worker 3 and vice-versa.\n",
    "\n",
    "\n",
    "* A `RemoteChannel`, however, can put and take values across workers. A `RemoteChannel` can be thought of as a handle to a `Channel`.\n",
    "\n",
    "\n",
    "* Any process with a reference to a `RemoteChannel` can put and take items from the channel. Data is automatically sent to (or retrieved from) the process a `RemoteChannel` is associated with.\n",
    "\n",
    "\n",
    "* The process id, pid, associated with a `RemoteChannel` identifies the process where the backing store, i.e., the backing Channel exists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nworkers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "addprocs(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function do_something()\n",
    "    rc = RemoteChannel(()->Channel{Int}(10)) # lives on the master\n",
    "    @sync for p in workers()\n",
    "        @spawnat p put!(rc, myid())\n",
    "    end\n",
    "    rc\n",
    "end\n",
    "\n",
    "r = do_something()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isready(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while isready(r)\n",
    "    @show take!(r)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ecosystem also contains a couple of tools, that make data transfer even simpler. See for example [ParallelDataTransfer.jl](https://github.com/ChrisRackauckas/ParallelDataTransfer.jl/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## High-level tools: `@distributed` and `pmap`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far we have seen some of the fundamental building blocks for distributed computing in Julia. However, in practice, one wants to think as little as possible about how to distribute the work and explicitly spawn tasks.\n",
    "\n",
    "Fortunately, many useful parallel computations do not require (much) data movement at all. A common example is a direct Monte Carlo simulation, where multiple processes can handle independent simulation trials simultaneously. (We'll get to that later in the exercises!)\n",
    "\n",
    "Julia provides **high-level convenience** tools to\n",
    " * parallelize loops ([**`@distributed`**](https://docs.julialang.org/en/v1/stdlib/Distributed/#Distributed.@distributed)) and\n",
    " * apply a function to all elements of a collection ([**`pmap`**](https://docs.julialang.org/en/v1/stdlib/Distributed/#Distributed.pmap))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Distributed loops (`@distributed`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Distributed, BenchmarkTools; rmprocs(workers()); addprocs(4); nworkers()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example: Reduction\n",
    "\n",
    "Task: Counting heads in a series of coin tosses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function count_heads_loop(n)\n",
    "    c = 0\n",
    "    for i = 1:n\n",
    "        c += rand(Bool)\n",
    "    end\n",
    "    return c\n",
    "end\n",
    "\n",
    "N = 200_000_000\n",
    "@btime count_heads_loop($N);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that these kinds of computations are called **reductions** (with `+` being the **reducer function**)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_heads_reduce(n) = mapreduce(i -> rand(Bool), +, 1:n)\n",
    "@btime count_heads_reduce($N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function count_heads_distributed_loop(n)\n",
    "    c = @distributed (+) for i in 1:n\n",
    "        Int(rand(Bool))\n",
    "    end\n",
    "    return c\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@btime count_heads_distributed_loop($N);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distributed version is about **4x faster**, which is all we could hope for."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With `@distributed` the work is **evenly distributed** between the workers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function count_heads_distributed_verbose(n)\n",
    "    c = @distributed (+) for i in 1:n\n",
    "        x = Int(rand(Bool))\n",
    "        println(x);\n",
    "        x\n",
    "    end\n",
    "    c\n",
    "end\n",
    "\n",
    "count_heads_distributed_verbose(8);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, by using `@distributed` we let Julia decide how to split up the work and can't control it ourselves."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A common mistake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function g(n)\n",
    "    a = 0\n",
    "    @distributed (+) for i in 1:n\n",
    "        a += 1\n",
    "    end\n",
    "    a\n",
    "end\n",
    "\n",
    "a = g(10);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do you expect the value of `a` to be?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example: `SharedArray`s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apart from `@distributed (reducer) ...` there also is a `@distributed for ...` form. The latter is **non-blocking** and returns a `Task`. (You can think of it as a distributed version of `@spawn` for all the iterations.)\n",
    "\n",
    "However, since the loop body will be executed on different processes, one must be careful to operate on data structures that are available on all processes (similar to the mistake highlighted above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function square_broken()\n",
    "    A = collect(1:10)\n",
    "    @sync @distributed for i in eachindex(A)\n",
    "        A[i] = A[i]^2\n",
    "    end\n",
    "    return A\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "square_broken()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To actually make all processes operate on the same array, one can use a `SharedArray`. For this to work, the **processes need to live on the same host**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@everywhere using SharedArrays # must be loaded everywhere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = rand(3,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = SharedArray(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function square!(X)\n",
    "    for i in eachindex(X)\n",
    "        sleep(0.001) # mimicing some computational cost\n",
    "        X[i] = X[i]^2\n",
    "    end\n",
    "end\n",
    "\n",
    "function square_distributed!(X)\n",
    "    @sync @distributed for i in eachindex(X)\n",
    "        sleep(0.001) # mimicing some computational cost\n",
    "        X[i] = X[i]^2\n",
    "    end\n",
    "end\n",
    "\n",
    "A = rand(10,10)\n",
    "S = SharedArray(A)\n",
    "\n",
    "@btime square!(A);\n",
    "@btime square_distributed!($S);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parallel map: `pmap`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `square!` functions above are typical `map` operations where a function `f` is applied to all elements of a collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map(x->x^2, 1:10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Such a pattern can be parallelized in Julia via the high-level function `pmap` (\"parallel map\")."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example: Singular values of multiple matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Distributed, BenchmarkTools; rmprocs(workers()); addprocs(4); nworkers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@everywhere using LinearAlgebra\n",
    "\n",
    "M = Matrix{Float64}[rand(200,200) for i = 1:10];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svdvals(rand(2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map(svdvals, M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmap(svdvals, M)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check that this indeed utilized multiple workers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmap(M) do m\n",
    "    println(myid());\n",
    "    svdvals(m)\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@btime map($svdvals, $M);\n",
    "@btime pmap($svdvals, $M);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When to choose which? (`@distributed` vs `pmap`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Julia's `pmap` is designed for the case where\n",
    "\n",
    "* one wants to apply **a function to a collection**,\n",
    "* each function call does a **larger amount of work**, and/or\n",
    "* the **workload is non-uniform** (load-balancing).\n",
    "\n",
    "On the other hand, `@distributed` is good for\n",
    "\n",
    "* **reductions**, like sums, where\n",
    "* **each iteration may be tiny**, i.e. perhaps only summing two numbers, and/or\n",
    "* each iteration **takes about the same time** (uniform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## High-level array abstractions: [DistributedArrays.jl](https://github.com/JuliaParallel/DistributedArrays.jl)\n",
    "\n",
    "In a `DArray`, each process has local access to just a chunk of the data, and no two processes share the same chunk. Processes can be on different hosts.\n",
    "\n",
    "Distributed arrays are for example useful if\n",
    "\n",
    "* Expensive calculations should be performed in parallel on parts of the array on different hosts.\n",
    "* The data doesn't fit into the local machines memory (i.e. loading big files in parallel)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Distributed, BenchmarkTools; rmprocs(workers());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure that all workers use the same Julia environment\n",
    "addprocs(4; exeflags=\"--project\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check\n",
    "@everywhere @show Base.active_project()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@everywhere using DistributedArrays, LinearAlgebra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = Matrix{Float64}[rand(200,200) for i = 1:10];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = distribute(M)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which workers hold parts of D?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "procs(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workers()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which parts do they hold?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "localpart(D) # the master doesn't hold anything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which parts do they hold?\n",
    "for p in workers()\n",
    "    println(@fetchfrom p DistributedArrays.localindices(D))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@btime map($svdvals, $M);\n",
    "@btime map($svdvals, $D);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@btime pmap($svdvals, $M);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Actual* distributed computing: Comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating workers on other machines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far we have worked with multiple process on the same system, because we simply used `addprocs(::Integer)`. To put worker processes on other machines, e.g. nodes of a cluster, we need to modify the initial `addprocs` call appropriately.\n",
    "\n",
    "In Julia, starting worker processes is handled by [ClusterManagers](https://docs.julialang.org/en/v1/manual/distributed-computing/#ClusterManagers).\n",
    "\n",
    "* The default one is `LocalManager`. It is automatically used when running `addprocs(i::Integer)` and we have implicitly used it already.\n",
    "* Another important one is `SSHManager`. It is automatically used when running `addprocs(hostnames::Array)`, e.g. `addprocs([\"node123\", \"node456\"])`. The only requirement is a **passwordless ssh access** to all specified hosts.\n",
    "* Cluster managers for SLURM, PBS, and others are provided in [ClusterManagers.jl](https://github.com/JuliaParallel/ClusterManagers.jl). For SLURM, this will make `addprocs` use `srun` under the hood."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Demonstrate in terminal from thp node*\n",
    "\n",
    "```julia\n",
    "using Distributed\n",
    "\n",
    "addprocs([\"l93\", \"l94\"])\n",
    "\n",
    "@everywhere println(gethostname())\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One can also start multiple processes on different machines:\n",
    "```julia\n",
    "addprocs([(\"node123\", 2), (\"node456\", 3)]) # starts 2 workers on node123 and 3 workers on node456\n",
    "\n",
    "# Use :auto to start as many processes as CPU threads are available\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Be aware of different paths:**\n",
    "* By default, `addprocs` expects to find the julia executable on the remote machines under the same path as on the host (master).\n",
    "* It will also try to `cd` to the same folder (set the working directory).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see from `?addprocs`, `addprocs` takes a bunch of keyword arguments, two of which are of particular importance in this regard:\n",
    "\n",
    "* `dir`: working directory for the worker processes\n",
    "* `exename`: path to julia executable (potentially augmented with pre-commands) for the worker processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleanup\n",
    "rmprocs(workers())"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Julia 1.8.0",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

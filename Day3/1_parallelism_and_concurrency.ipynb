{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parallel Computing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General thoughts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parallel computing is a programming method that **harnesses the power of multiple processors (typically CPU cores) at once**.\n",
    "\n",
    "There are many types of parallelism, some of which are (from micro to macro)\n",
    "\n",
    "* **Instruction level parallelism** (e.g. SIMD)\n",
    "* **Multi-threading** (shared memory)\n",
    "* **Multi-processing** (shared system memory)\n",
    "* **Distributed processing** (typically no shared memory)\n",
    "\n",
    "**Import note before we start: At the center of an efficient parallel code is a fast serial code!!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why go parallel?\n",
    "\n",
    "<img src=\"../imgs/42-years-processor-trend.svg\" width=700px>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When to go parallel?\n",
    "\n",
    "* If parts of your (optimized!) serial code aren't fast enough.\n",
    "  * note that parallelization typically increases the code complexity\n",
    "* If your system has multiple execution units (CPU threads, GPU threads, ...).\n",
    "  * particularly import on large supercomputers but also already on modern desktop computers and laptops."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many CPU threads / cores do I have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Hwloc\n",
    "Hwloc.num_physical_cores()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that there may be more than one CPU thread per physical CPU core (e.g. hyperthreading)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sys.CPU_THREADS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many CPU threads / cores does Hawk have?\n",
    "\n",
    "[Hawk has about 720k CPU cores!](https://www.hlrs.de/solutions/systems/hpe-apollo-hawk)\n",
    "\n",
    "Even if you only use a single node you have access to 128 CPU cores (64 per CPU). Hence, if you would use only a single core, the node utilization would be less than 1%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Amdahl's law"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive strong scaling expectation: I have 4 cores, give me my 4x speedup!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">If $p$ is the fraction of a code that can be parallelized than the maximal theoretical speedup by parallelizing on $n$ cores is given by\n",
    ">$$ F(n) = 1/(1-p + p/n) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Plots\n",
    "F(p,n) = 1/(1-p + p/n)\n",
    "\n",
    "pl = plot()\n",
    "for p in reverse(sort(vcat(0.2:0.2:1, [0.9, 0.95])))\n",
    "    plot!(pl, n -> F(p,n), 1:16, lab=\"$(Int(p*100))%\", lw=2,\n",
    "        legend=:topleft, xlab=\"number of cores\", ylab=\"parallel speedup\", frame=:box)\n",
    "end\n",
    "pl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Parallel computing](https://docs.julialang.org/en/v1/manual/parallel-computing/) in Julia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Julia provides support for all types of parallelism mentioned above (same order)\n",
    "\n",
    "* `@simd`, [SIMD.jl](https://github.com/eschnett/SIMD.jl), [LoopVectorization.jl](https://github.com/JuliaSIMD/LoopVectorization.jl)\n",
    "* `Threads.@threads`, `Threads.@spawn`, [FLoops.jl](https://github.com/JuliaFolds/FLoops.jl), [ThreadsX.jl](https://github.com/tkf/ThreadsX.jl) ...\n",
    "* `@spawnat`, `@fetch`, `RemoteChannel`, `SharedArray`\n",
    "* `@spawnat`, `@fetch`, `RemoteChannel`, [DistributedArrays.jl](https://github.com/JuliaParallel/DistributedArrays.jl), [MPI.jl](https://github.com/JuliaParallel/MPI.jl)\n",
    "\n",
    "With supercomputing in mind, we will start by focusing on multi-process parallelism which allows us to utilize multiple cores on the same or different nodes/machines (distributed computing).\n",
    "\n",
    "But before we do, it's instructive to take a closer look at **tasks**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, Julia waits for every command to finish (\"**blocking**\") and run everything sequentially.\n",
    "\n",
    "**Tasks** are a control flow feature that allows computations to be suspended and resumed in a flexible manner to implement **cooperative multitasking**. (This feature is sometimes called by other names, such as coroutines, green-, or lightweight threads.)\n",
    "\n",
    "Tasks are managed by Julia and can be run in a **concurrent** fashion.\n",
    "\n",
    "> **Concurrency** means executing multiple tasks at the same time but not necessarily simultaneously.\n",
    "\n",
    "An important use case is **asynchronous I/O**, which is typically slow. Examples are\n",
    " * **multiple user input** (Why not already process some of the input?)\n",
    " * **data dumping to disk** (Maybe it's possible to continue a calculation?)\n",
    " * **receiving calculations from worker processes**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `@async` and `@sync`\n",
    "\n",
    "We can create and schedule a task for asynchronous execution with the [`@async` macro](https://docs.julialang.org/en/v1/base/parallel/#Base.@async)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What this means is that for whatever falls into its scope, Julia will start a task to then proceed to whatever comes next in the script without waiting for the task to complete (\"**non-blocking**\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@time sleep(2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@time @async sleep(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Julia allows the script to proceed (and the `@time` macro to fully execute) without waiting for the task (in this case, sleeping for two seconds) to complete."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the partner macro `@sync` to synchronize, that is wait for all encapsulated tasks. (see `?@sync`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@time @sync @async sleep(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, here it doesn't make much sense to write `@sync @async` - we could simply drop it altogether. A better example is the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@time @sync begin\n",
    "    @async sleep(2.0)\n",
    "    @async sleep(2.0)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = rand(1000,1000)\n",
    "B = rand(1000,1000)\n",
    "\n",
    "t = @async A * B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wait(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fetch(t)"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Julia 1.8.0",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
